\documentclass[../relazione.tex]{subfiles}
\graphicspath{{\subfix{../images/}}}
\begin{document}
\section{Implementazione efficiente}
Per la seconda implementazione si è modificata la matrice di adiacenza in una matrice rettangolare in cui la colonna \textit{i-esima} contiene i riferimenti ai figli del nodo \textit{i-esimo}.

Inoltre per diminuire ulteriormente i tempi di ricerca all'interno della matrice rettangolare, si è creata anche una matrice speculare che nella colonna \textit{i-esima} contiene i riferimenti ai genitori del nodo \textit{i-esimo}.

Il resto dell'algoritmo è rimasto identico ad eccezione dei cambiamenti necessari e dovuti alla nuova struttura della matrice di adiacenza.

\subsection{Fase 1 - Ricerca degli entrypoint}
Grazie alla nuova struttura per verificare che un nodo sia un entrypoint è sufficiente controllare che la prima posizione della colonna relativa al nodo in esame abbia almeno un elemento, cosa che si traduce nel controllare che il primo elemento della colonna esista. 
\begin{lstlisting}[language=C++, caption={Find entrypoints kernel II},captionpos=b]
kernel void entry_discover_rectangular(const int n_nodes, global edge_t* restrict edges, volatile global int* n_entries, global int* entries)
{
	int current_node_index = get_global_id(0);
	if (current_node_index >= n_nodes) return;

	if (edges[matrixToArrayIndex] <= -1)
		entries[i] = 1;
}
\end{lstlisting}

\subsection{Fase 2 - Calcolo delle metriche}
La differenza rispetto alla prima implementazione risiede solo nel diverso accesso alla matrice di adiacenza.

\begin{lstlisting}[language=C++, caption={Compute metrics kernel II},captionpos=b]
kernel void compute_metrics_rectangular(global int* restrict nodes, global int* queue_, global int* next_queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, volatile global int2* metriche, const int max_adj_dept)
{
	int current_node_index = get_global_id(0);
	if(current_node_index >= n_nodes) return;
	
	[...] //omissis of various security checks
	
	for (int j = 0; j < max_adj_dept; j++) {
		int parentAdjIndex = j;
		matrixToArrayIndex = matrix_to_array_indexes(parentAdjIndex, current_node_index, n_nodes);
		int edge_weight = 1;
		int parent_index = edges[matrixToArrayIndex];
		if (parent_index >= 0){
			int weight_with_this_parent = edge_weight + metriche[parent_index].x + nodes[current_node_index];
			int level_with_this_parent = metriche[parent_index].y + 1;
			metrics_with_this_parent = (int2)(weight_with_this_parent, level_with_this_parent);
			if (gt(metrics_with_this_parent, metriche[current_node_index]))
				metriche[current_node_index] = metrics_with_this_parent;
		}
		int child_index = edges_reverse[matrixToArrayIndex];
		if (child_index >= 0)
			atomic_inc(&next_queue_[child_index]);
	}
}
\end{lstlisting}

Anche in questo caso il kernel deve essere eseguito dall'host più volte fin quando non si produrrà una \textit{next\_queue} identica alla precedente in cui quindi non ci sono stati cambiamenti.

\subsection{Fase 3 - ordinamento dei task}
In questa fase non è stato modificato nulla in quanto si lavora su un array di metriche che non ha alcuno correlazione alla matrice di adiacenza e che quindi non è influenzata dalle modifiche a quest'ultima,

\subsection{Considerazioni}
La complessità di questa seconda implementazione è $O(n)$ per la ricerca degli entrypoint, $O(n \cdot max\_adj\_dept)$ per il calcolo delle metriche e $O(n\ log\ n)$.
In definitiva, l'algoritmo ha complessità $O(n \cdot max\_adj\_dept)$, dove $n$ è il numero di nodi e $max\_adj\_dept$ è il numero massimo di figli che un nodo può avere.

\subsection{Variazioni}
Anche in questo caso si è provato a vettorizzare il kernel per abbassare i tempi di runtime che, comunque, rispetto alla prima implementazione sono già più bassi di diversi ordini di grandezza.

Sarebbe stato inutile inoltre verificare eventuali variazioni con la matrice trasposta, in quanto già nell'implementazione base sfruttiamo due matrici di adiacenza, una che tiene traccia dei figli di ogni nodo ed una speculare che tiene traccia dei genitori.

Riportiamo di seguito i tempi di runtime dei kernel con la nuova implementazione e successivamente il confronto tra il \textit{compute\_metrics} più basso della prima implementazione e quello della seconda implementazione compresa la sua variante vettorizzata.

Anche in questo caso per i testi si è usato un dataset di 4096 task in esecuzione su una GPU NVIDIA GTX 1650 per 20 esecuzioni di cui successivamente è stata calcolata la media dei tempi di runtime.

\begin{figure}[H]
\begin{subfigure}{0.5\textwidth}
\begin{tikzpicture}
\begin{axis}[
symbolic x coords={
Rectangular,
Vec4 rectangular},
xtick=data,
x tick label style={rotate=45,anchor=east},
nodes near coords,
every node near coord/.append style={rotate=90, anchor=center},
ylabel=Runtime (ms),
legend style={at={(0.5, 0.85)}, anchor=west},
ybar=0pt,
legend cell align={left},
enlarge x limits=1,
enlarge y limits=0,
width=7.5cm,
]
\addplot+[every node near coord/.append style={yshift=10pt, xshift=30pt}] coordinates { %entries discover
(Rectangular, 0.04)
(Vec4 rectangular, 0.04)
};
\addplot+[every node near coord/.append style={xshift=0pt, anchor=west}] coordinates { %compute metrics
(Rectangular, 299.91)
(Vec4 rectangular, 31.99)
};
\addplot+[every node near coord/.append style={yshift=-10pt, xshift=0pt}] coordinates { %mergesort
(Rectangular, 1.91)
(Vec4 rectangular, 1.98)
};
\legend{entry\_discover, compute\_metrics, merge\_sort}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\caption{Tempi di runtime della seconda implementazione}

\begin{subfigure}{0.5\textwidth}
\begin{tikzpicture}
\begin{axis}[
symbolic x coords={
Standard transpose,
Rectangular,
Vec4 rectangular},
xtick=data,
x tick label style={rotate=45,anchor=east},
nodes near coords,
every node near coord/.append style={rotate=90, anchor=center},
ylabel=Runtime (ms),
legend style={at={(0.5, 0.85)}, anchor=west},
ybar=0pt,
legend cell align={left},
enlarge x limits=0.3,
enlarge y limits=0,
width=7.5cm,
]
\addplot+[every node near coord/.append style={xshift=0pt, anchor=west}] coordinates { %compute metrics
(Standard transpose, 2850.95)
(Rectangular, 299.91)
(Vec4 rectangular, 31.99)
};
\legend{compute\_metrics}
\end{axis}
\end{tikzpicture}
\end{subfigure}
\caption{Tempi di runtime della prima e della seconda implementazione a confronto} \label{fig:M1}
\end{figure}

Come si può vedere quindi, i tempi sono notevolmente migliorati semplicemente cambiando la modalità di memorizzazione e accesso ai dati. 

\end{document}