#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics : enable
#include "../app_globals.h"

#pragma inline
int matrix_to_array_indexes(int i, int j, int row_len){
	return i * row_len + j;
}

#pragma inline
bool areEquals(local const int4 *a, local const int4*b, int len){
	bool equal = true;
	#pragma unroll
	for(int i=0; i<len; i++){
		if(any(a[i] != b[i])){
			equal = false;
			break;
		}
	}
	return equal;
}

#pragma inline
int compare (metrics_tt V1, metrics_tt V2){
	if(V1.y == V2.y){
		return (V1.x > V2.x) ? 1 : -1; //NOTA: è diverso da quello implementato nel sort, perché in quel caso abbiamo dei criteri diversi su come definire un elemento maggiore di un altro.
	}
	return (V1.y > V2.y) ? 1 : -1;
}

#pragma inline
int gt (metrics_tt V1, metrics_tt V2){
	return compare(V1, V2) > 0;
}

#pragma inline
bool isEmpty(local const int4 *v, int len, int4 default_v, int starting_from){
	#pragma unroll
	for (int i = starting_from; i < len; i++)
	{
		if(v[i].x != default_v.x || v[i].y != default_v.y || v[i].z != default_v.z || v[i].w != default_v.w){
			return false;
		}
	}
	return true;
}

#pragma inline
bool isEmptyGlobal(global const int4 *v, int len, int4 default_v, int starting_from){
	#pragma unroll
	for (int i = starting_from; i < len; i++)
	{
		if(v[i].x != default_v.x || v[i].y != default_v.y || v[i].z != default_v.z || v[i].w != default_v.w){
			return false;
		}
	}
	return true;
}

// inline void swap(int4 *a, int4 *b) {
// 	int4 tmp;
// 	tmp = *b;
// 	*b = *a;
// 	*a = tmp;
// }
inline void swap(local int4 *a, local int4 *b) {
	int4 tmp;
	tmp = *b;
	*b = *a;
	*a = tmp;
}

void print(global int4 *v, int len, bool withIndexes){
	for (int i = 0; i < len; i++)
	{
		if(withIndexes)
			printf("%d:", i);	
		printf("{%d,%d,%d,%d} - ", v[i].x, v[i].y, v[i].z, v[i].w);	
	}
	
	printf("\n");
}

#pragma inline
bool isEven(int a){
	return (a%2) == 0;
}

#pragma inline
bool firstOfFour(int a){
	return (a%4) == 0;
}


// Comincio la BFS.

	//int *q = alloc(); //TODO: Come faccio a creare una coda?
	//Ha senso creare una coda in local memory visto che la procedura BFS va richiamata ricorsivamenteper ogni task nella coda
	//Ogni WI potrebbe aggiungere man mano i task alla coda, mentre altri WI processano questi nuovi task in coda?
	//


	//PER OGNI NODO:
		//BREADTH FIRST SEARCH PER CALCOLARE I LIVELLI, CIOÈ GLI INSIEMI DI TASK INDIPENDENTI E CHE QUINDI POSSONO ESSERE PARALLELIZZATE
		
		//BREADTH FIRST SEARCH PER CALCOLARE IL COSTO COMPLESSIVO DI UN NODO DATI I SUOI PARENT. (DTC - DATA TRANSFER COST)
		
		//(BREADTH FIRST SEARCH)? PER CALCOLARE RANK DEI SUOI PARENT E SCEGLIERE IL MAX. (RPT - RANK of PREDECESSOR TASK)
		
		//CALCOLO DEL SUO RANK DATO DA: ROUND(ACC+DTC+RPT); (con ACC - AVERAGE COMPUTATIONAL COST, costante nel nostro caso ed è la quantità di dati trasmessi, perché assumiamo che tutti i processori siano uguali)


	//ALLA FINE LA PRIORITÀ È DATA DA:
		//LIVELLO PIÙ BASSO
		
		//SE STESSO LIVELLO ALLORA RANK PIÙ ALTO

		//SE STESSO RANK ALLORA ACC PIÙ BASSO


	//IL PROCESSORE VIENE ASSEGNATO IN BASE:
		//PER OGNI TASK SI SCEGLIE IL PROCESSORE CON EFT - ESTIMATED FINAL TIME PIÙ PICCOLO, CHE VIENE CALCOLATO RICORSIVAMENTE A PARTIRE DAI PARENT DEL TASK


//TODO: in realtà parent e child alla fine di questo kernel sono invertiti perchè adj contiene gli edge da child a parent e non il viceversa.
kernel void compute_metrics_standard_with_rectangular_matrix_no_reduction(global int* restrict nodes, global int* queue_, global int* next_queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int el_in_queue)
{
	int i = get_global_id(0);
	int current_node_index = i;
	if (i >= n_nodes) {
		return;
	}

	if (queue_[current_node_index] <= 0)return;
	//se sono stato messo in coda un numero di volte pari al numero dei miei parent, allora posso proseguire, altrimenti non faccio nulla.
	//in particolare proseguire significa calcolare la metrica dai miei parent scegliendo quella più pesante e mettere in coda i miei figli.

	//per controllare di essere stato messo in coda un numero sufficiente di volte, l'metrics_tt delle metriche viene inizializzato con il numero dei parent nella y.
	//in questo modo ogni volta che il nodo viene messo in coda può decrementare il suo y fino a quando non diventa 0, a qual punto può procedere al calcolo del rank.
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	metriche[i].y = metriche[i].y - queue_[current_node_index];
	//queue_[current_node_index] = 0; //Inutile perchè la queue vine resa next queue che a sua volta viene resettata all fine del ciclo.
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	if (metriche[i].y > 0)return;
	metriche[current_node_index] = (metrics_tt)(nodes[current_node_index], 0,current_node_index);
	//calcolo il livello del nodo attuale e il suo rank a partire dai parent
	metrics_tt metrics_with_this_parent;
	int matrixToArrayIndex;
#pragma unroll
	for (int j = 0; j < max_adj_dept; j++) {
		/* Calcolo la metrica del nodo a partire dai parent. */
		int parentAdjIndex = j;
#if TRANSPOSED_ADJ
		matrixToArrayIndex = matrix_to_array_indexes(i, parentAdjIndex, max_adj_dept);
#else
		matrixToArrayIndex = matrix_to_array_indexes(parentAdjIndex, i, n_nodes);
#endif // TRANSPOSED_ADJ
		int edge_weight = edges_weights[matrixToArrayIndex];
		int parent_index = edges[matrixToArrayIndex]; //controllo tutti i parent di current_node
		if (parent_index >= 0){ //essendo adj matrice rettangolare appena trovo il la prima riga vuota sono sicuro che sotto non ci siano altri child(anche se in questo caso li chiamiamo parent)
			int weight_with_this_parent = edge_weight + metriche[parent_index].x + nodes[current_node_index];
			int level_with_this_parent = metriche[parent_index].y + 1;
			metrics_with_this_parent = (metrics_tt)(weight_with_this_parent, level_with_this_parent,current_node_index);
			if (gt(metrics_with_this_parent, metriche[current_node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
				metriche[current_node_index] = metrics_with_this_parent;
		}
		/*Aggiugno i child alla coda*/
		int child_index = edges_reverse[matrixToArrayIndex]; //controllo tutti i parent di current_node
		if (child_index >= 0) //essendo adj matrice rettangolare appena trovo il la prima riga vuota sono sicuro che sotto non ci siano altri child(anche se in questo caso li chiamiamo parent)
			atomic_inc(&next_queue_[child_index]);
	}

}


kernel void reset(global int* restrict vector, const int nels, const int default_value) {
	int i = get_global_id(0);
	if (i >= nels)
		return;
		
	vector[i] = default_value;
}

kernel void compute_metrics_standard_with_rectangular_matrix(global int* restrict nodes, global int* queue_, global int* next_queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO,TASK_ID>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	int i = get_global_id(0);
	int current_node_index = i;
	

	if (i >= n_nodes) {
		return;
	}

	if (queue_[current_node_index] <= 0)return;
	//se sono stato messo in coda un numero di volte pari al numero dei miei parent, allora posso proseguire, altrimenti non faccio nulla.
	//in particolare proseguire significa calcolare la metrica dai miei parent scegliendo quella più pesante e mettere in coda i miei figli.

	//per controllare di essere stato messo in coda un numero sufficiente di volte, l'metrics_tt delle metriche viene inizializzato con il numero dei parent nella y.
	//in questo modo ogni volta che il nodo viene messo in coda può decrementare il suo y fino a quando non diventa 0, a qual punto può procedere al calcolo del rank.
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	metriche[i].y = metriche[i].y - queue_[current_node_index];
	//queue_[current_node_index] = 0; //Inutile perchè la queue vine resa next queue che a sua volta viene resettata all fine del ciclo.
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	if (metriche[i].y > 0)return;
	int edge_weight = 0;
#pragma unroll
	for (int j = 0; j < max_adj_reverse_dept; j++) {
		int matrixToArrayIndex = matrix_to_array_indexes(j,current_node_index, n_nodes);
		if(edges_weights[matrixToArrayIndex] > -1){
			edge_weight += edges_weights[matrixToArrayIndex];
		}
	}

	metriche[current_node_index] = (metrics_tt)(edge_weight + nodes[current_node_index], 0,current_node_index);
	//calcolo il livello del nodo attuale e il suo rank a partire dai parent
	metrics_tt metrics_with_this_parent;
	int matrixToArrayIndex;
	

	//printf("Task: %d ha DTC: %d \n", current_node_index, edge_weight);

#pragma unroll
	for (int j = 0; j < max_adj_dept; j++) {
		/* Calcolo la metrica del nodo a partire dai parent. */
		int parentAdjIndex = j;
#if TRANSPOSED_ADJ
		matrixToArrayIndex = matrix_to_array_indexes(i, parentAdjIndex, max_adj_dept);
#else
		matrixToArrayIndex = matrix_to_array_indexes(parentAdjIndex, i, n_nodes);
#endif // TRANSPOSED_ADJ
		int parent_index = edges[matrixToArrayIndex]; //controllo tutti i parent di current_node
		if (parent_index >= 0){ //essendo adj matrice rettangolare appena trovo il la prima riga vuota sono sicuro che sotto non ci siano altri child(anche se in questo caso li chiamiamo parent)
			int weight_with_this_parent = edge_weight + metriche[parent_index].x + nodes[current_node_index];
			int level_with_this_parent = metriche[parent_index].y + 1;
			metrics_with_this_parent = (metrics_tt)(weight_with_this_parent, level_with_this_parent,current_node_index);
			if (gt(metrics_with_this_parent, metriche[current_node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
				metriche[current_node_index] = metrics_with_this_parent;
		}
	}
#pragma unroll
	for (int j = 0; j < max_adj_reverse_dept; j++) {
		/*Aggiugno i child alla coda*/
		int parentAdjIndex = j;
#if TRANSPOSED_ADJ
		matrixToArrayIndex = matrix_to_array_indexes(i, parentAdjIndex, max_adj_reverse_dept);
#else
		matrixToArrayIndex = matrix_to_array_indexes(parentAdjIndex, i, n_nodes);
#endif // TRANSPOSED_ADJ

		int child_index = edges_reverse[matrixToArrayIndex]; //controllo tutti i parent di current_node
		if (child_index >= 0) //essendo adj matrice rettangolare appena trovo il la prima riga vuota sono sicuro che sotto non ci siano altri child(anche se in questo caso li chiamiamo parent)
			atomic_inc(&next_queue_[child_index]);
	}
}



bool compute_metrics_vectorized_rectangular_item(global int* restrict nodes, global int4* queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	int work_item = get_global_id(0);
	int something_changed = false;
	if (work_item >= ceil(n_nodes / 4.0)) {
		return something_changed;
	}
	int indexes_to_analyze[4] = { 1, 1, 1, 1 };

	for (int i = 0; i < 4; i++) {
		int node_index = work_item * 4 + i;
		int node;
		volatile global int* nodes = &(queue_[work_item]);//TODO: funziona solo se potenza del due, per n_nodes diversi da problemi.

		node = nodes[i];
		if (node != 0)indexes_to_analyze[i] = 0; //Non è ancora da analizzare, qualche parent non ha finito l'esecuzione (>0). O è già stato analizzato (-1).
		else {
			// printf("analizzo: %d\n", node_index);
			metriche[node_index].y = metriche[node_index].y - node;
			atomic_dec(&(nodes[i])); //lo porto a -1 così non ciclo all'infinito.
		}

		// if(metriche[node_index].y > 0)indexes_to_analyze[i] = 0; //non ancora tutti i parent sono stati analizzati.
		// else metriche[node_index] = (metrics_tt)(nodes[node_index],0);
	}

	if (!indexes_to_analyze[0] && !indexes_to_analyze[1] && !indexes_to_analyze[2] && !indexes_to_analyze[3]) return something_changed;

	metrics_tt metrics_with_this_parent;
	int matrixToArrayIndex;
#pragma unroll
	for (int i = 0; i < 4; i++) {
		if (!indexes_to_analyze[i]) continue;
	
		int node_index = work_item * 4 + i;
		int edge_weight = 0;
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int matrixToArrayIndex = matrix_to_array_indexes(j, node_index, n_nodes);
			if(edges_weights[matrixToArrayIndex] > -1){
				edge_weight += edges_weights[matrixToArrayIndex];
			}
		}

		metriche[node_index] = (metrics_tt)(edge_weight + nodes[node_index],0,node_index);

#pragma unroll
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int parent = j;

#if TRANSPOSED_ADJ
			matrixToArrayIndex = matrix_to_array_indexes(node_index, parent, max_adj_reverse_dept);
#else
			matrixToArrayIndex = matrix_to_array_indexes(parent, node_index, n_nodes);
#endif // TRANSPOSED_ADJ

			int parentIndex = edges[matrixToArrayIndex]; //controllo tutti i parent di current_node
			if (parentIndex >= 0) {
				int weight_with_this_parent = edge_weight + metriche[parentIndex].x + nodes[node_index];
				int level_with_this_parent = metriche[parentIndex].y + 1;
				metrics_with_this_parent = (metrics_tt)(weight_with_this_parent, level_with_this_parent, node_index);
				if (gt(metrics_with_this_parent, metriche[node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
					metriche[node_index] = metrics_with_this_parent;
			}
		}
#pragma unroll
		for (int j = 0; j < max_adj_dept; j++) {
			int parent = j;
			int node_index = work_item * 4 + i;
#if TRANSPOSED_ADJ
			matrixToArrayIndex = matrix_to_array_indexes(node_index, parent, max_adj_dept);
#else
			matrixToArrayIndex = matrix_to_array_indexes(parent, node_index, n_nodes);
#endif // TRANSPOSED_ADJ
			
			int childIndex = edges_reverse[matrixToArrayIndex];
			if (childIndex >= 0) { //TODO: prendi a quattro a quattro.
				// printf("%d parent di %d\n", node_index, child);
				int globalIndexStart = (int)(floor(j / 4.0));
				// printf("%d parent di %d -> %d\n", node_index, child, globalIndexStart);	
				volatile global int* four_next_nodes = &(queue_[globalIndexStart]);
				// printf("before ");
				// print(&queue_[globalIndexStart], 1, false);
				atomic_dec(&(four_next_nodes[childIndex - globalIndexStart * 4]));
				something_changed = true;
				// printf("after ");
				// print(&queue_[globalIndexStart], 1, false);
			}
		}
	}

	return something_changed;
}

kernel void compute_metrics_vectorized_rectangular(global int* restrict nodes, global int4* queue_, local int4* local_queue, local int4* local_queue_temp, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	local bool something_changed;
	int work_item = get_global_id(0);
	int work_item_local_index = get_local_id(0);
	int work_group_size = get_local_size(0);
	int work_group = get_group_id(0);
	//64 / 4 = 16 -> 16 elementi da gestire in totale, quindi diviso 32 work item e 1 workgroup.
	//128 / 4 = 32 -> 32 elementi da gestire in totale, quindi diviso 32 work item e 1 workgroup.
	//256 / 4 = 64 -> 64 elementi da gestire in totale, quindi diviso 32 work item e 2 workgroup.
	int global_queue_size = (int)ceil(n_nodes / 4.0);
	int local_queue_size = min(work_group_size, global_queue_size); //non è la lunghezza dalla coda globale ma la lunghezza di cui si deve occupare questo work group.

	bool work_item_outside_range = work_item >= global_queue_size || work_item_local_index >= local_queue_size;

	// printf("queue_size: %d\n", queue_size);
	// note: every work item must call this, read documentation for further details.
	// work_group_barrier(CLK_GLOBAL_MEM_FENCE);
	event_t e[2];
	e[0] = async_work_group_copy(local_queue, queue_ + work_group * local_queue_size, local_queue_size, NULL);
	e[1] = async_work_group_copy(local_queue_temp, queue_ + work_group * local_queue_size, local_queue_size, e[0]);
	wait_group_events(1, e);
	// work_group_barrier(CLK_LOCAL_MEM_FENCE);

	// if(work_item_local_index == 0) printf("priemo %d, %d, %d, %d\n", local_queue, queue_[0].y, work_group * local_queue_size, local_queue_size);

#pragma unroll
	do {
		// if(work_item_local_index == 0)printf("ciclo\n");
		// per ogni work item se il suo count è zero, allora: 
		// 1.calcolare la sua metrica
		// 2.decrementare il valore dei suoi child in coda globale e locale se in range.
		// 2.alt oppure invece di decrementare sia la global che la local, si può ricopiare la global in local ad ogni ciclo, 
		// 		in questo modo riusciamo anche a ricevere entuali aggiornamenti da altri work group.

		//Problema: è possbile che ci sia una dipendenza da un work group non ancora partito, quindi non devo controllare
		//			che la coda sia vuota, ma che non ci siano stati cambiamenti dall'ultimo ciclo.
		//			Inoltre devo stare attento che se analizzo un task perchè ha valore zero, non devo ricontrollarlo al prossimo ciclo,
		//			quindi devo usare un -1 per indicare i task con analisi completata.

		if (!work_item_outside_range)
			compute_metrics_vectorized_rectangular_item(nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);

		// work_group_barrier(CLK_GLOBAL_MEM_FENCE);
		// TODO: implementare a mano facendolo fare a tutti i WI(cosa che secondo il prof è più veloce)
		async_work_group_copy(local_queue, queue_ + work_group * local_queue_size, local_queue_size, NULL);
		// work_group_barrier(CLK_LOCAL_MEM_FENCE);

		if (work_item_local_index == 0) {
			something_changed = !areEquals(local_queue, local_queue_temp, local_queue_size);
			// print(local_queue_temp, local_queue_size, false);
			// printf("\n");
			// print(local_queue, local_queue_size, false);
		}
		// work_group_barrier(CLK_GLOBAL_MEM_FENCE);
		// work_group_barrier(CLK_LOCAL_MEM_FENCE);
		//TODO: implementa con bool di ritonro dalla funzione item
		async_work_group_copy(local_queue_temp, queue_ + work_group * local_queue_size, local_queue_size, NULL);
		e[0] = async_work_group_copy(local_queue, queue_ + work_group * local_queue_size, local_queue_size, NULL);
		e[1] = async_work_group_copy(local_queue_temp, queue_ + work_group * local_queue_size, local_queue_size, e[0]);
		wait_group_events(1, e);
	} while (something_changed);
}

/*optimized version of compute_metrics_vectorized_rectangular */
//todo: variabile globale samething cahnged che viene letta dall'host.
//oppure lanciare secondo kernel che controlla se coda vuoto in parallelo o anche in questo stesso kernel alla fine.
kernel void compute_metrics_vectorized_rectangular_v2(global int* restrict nodes, global int4* queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	local int something_changed;
	int something_changed_for_me;
	int work_item = get_global_id(0);
	int work_item_local_index = get_local_id(0);
	int work_group_size = get_local_size(0);
	int work_group = get_group_id(0);
	int global_queue_size = (int)ceil(n_nodes / 4.0);
	int local_queue_size = min(work_group_size, global_queue_size); //non è la lunghezza dalla coda globale ma la lunghezza di cui si deve occupare questo work group.

	bool work_item_outside_range = work_item >= global_queue_size || work_item_local_index >= local_queue_size;

#pragma unroll
	do {
		if (work_item_local_index == 0)
			something_changed = 0;

		if (!work_item_outside_range)
			something_changed_for_me = compute_metrics_vectorized_rectangular_item(nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);

		if (something_changed_for_me)
			something_changed = 1;

		barrier(CLK_LOCAL_MEM_FENCE);
	} while (something_changed > 0);
}


#pragma inline
bool compute_metrics_vectorized8_rectangular_item(const global int* restrict nodes, global int8* restrict queue_, const int n_nodes, const global edge_t* restrict edges, const global edge_t* restrict edges_reverse, const global edge_t* restrict edges_weights, global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	int work_item = get_global_id(0);
	int something_changed = false;
	if (work_item >= ceil(n_nodes / 8.0)) {
		return something_changed;
	}
	int indexes_to_analyze[8] = { 1, 1, 1, 1, 1, 1, 1, 1 };

#pragma unroll
	for (int i = 0; i < 8; i++) {
		int node_index = work_item * 8 + i;
		int node;
		global int* _nodes = &(queue_[work_item]);//TODO: funziona solo se potenza del due, per n_nodes diversi da problemi.

		node = _nodes[i];
		if (node != 0)indexes_to_analyze[i] = 0; //Non è ancora da analizzare, qualche parent non ha finito l'esecuzione (>0). O è già stato analizzato (-1).
		else {
			// printf("analizzo: %d\n", node_index);
			metriche[node_index].y = metriche[node_index].y - node;
			atomic_dec(&(_nodes[i])); //lo porto a -1 così non ciclo all'infinito.
		}

		// if(metriche[node_index].y > 0)indexes_to_analyze[i] = 0; //non ancora tutti i parent sono stati analizzati.
		// else metriche[node_index] = (metrics_tt)(_nodes[node_index],0);
	}

	if (!indexes_to_analyze[0] && !indexes_to_analyze[1] && !indexes_to_analyze[2] && !indexes_to_analyze[3] 
		&& !indexes_to_analyze[4] && !indexes_to_analyze[5] && !indexes_to_analyze[6] && !indexes_to_analyze[7]
		) return something_changed;

	metrics_tt metrics_with_this_parent;
	int matrixToArrayIndex;
	
#pragma unroll
	for (int i = 0; i < 8; i++) {
		if (!indexes_to_analyze[i]) continue;

		int node_index = work_item * 8 + i;
		int edge_weight = 0; 
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int matrixToArrayIndex = matrix_to_array_indexes(j, node_index, n_nodes);
			if(edges_weights[matrixToArrayIndex] > -1){
				edge_weight += edges_weights[matrixToArrayIndex];
			}
		}
		metriche[node_index] = (metrics_tt)(edge_weight + nodes[node_index],0,node_index);

#pragma unroll
		for (int j = 0; j < max_adj_dept; j++) {
			int parent = j;

#if TRANSPOSED_ADJ
			matrixToArrayIndex = matrix_to_array_indexes(node_index, parent, max_adj_dept);
#else
			matrixToArrayIndex = matrix_to_array_indexes(parent, node_index, n_nodes);
#endif // TRANSPOSED_ADJ
			int parentIndex = edges[matrixToArrayIndex]; //controllo tutti i parent di current_node
			//printf("parent: %d %d %d\n",node_index, parent, parentIndex);
			if (parentIndex >= 0) {
				int weight_with_this_parent = edge_weight + metriche[parentIndex].x + nodes[node_index];
				int level_with_this_parent = metriche[parentIndex].y + 1;
				metrics_with_this_parent = (metrics_tt)(weight_with_this_parent, level_with_this_parent,node_index);
				if (gt(metrics_with_this_parent, metriche[node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
					metriche[node_index] = metrics_with_this_parent;
			}
		}

#pragma unroll
		for (int j = 0; j < max_adj_reverse_dept; j++) {
			int parent = j;
			int node_index = work_item * 8 + i;
#if TRANSPOSED_ADJ
			matrixToArrayIndex = matrix_to_array_indexes(node_index, parent, max_adj_reverse_dept);
#else
			matrixToArrayIndex = matrix_to_array_indexes(parent, node_index, n_nodes);
#endif // TRANSPOSED_ADJ
			int childIndex = edges_reverse[matrixToArrayIndex];
			if (childIndex >= 0) { //TODO: prendi a quattro a quattro.
				// printf("%d parent di %d\n", node_index, child);
				int globalIndexStart = (int)(floor(j / 8.0));
				// printf("%d parent di %d -> %d\n", node_index, child, globalIndexStart);	
				global int* four_next_nodes = &(queue_[globalIndexStart]);
				// printf("before ");
				// print(&queue_[globalIndexStart], 1, false);
				atomic_dec(&(four_next_nodes[childIndex - globalIndexStart * 8]));
				something_changed = true;
				// printf("after ");
				// print(&queue_[globalIndexStart], 1, false);
			}
		}
	}

	return something_changed;
}

//kernel void compute_metrics_vectorized8_rectangular(global int* restrict nodes, global int8* queue_, const int n_nodes, global edge_t* restrict edges, global edge_t* restrict edges_reverse, global edge_t* restrict edges_weights, volatile global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
kernel void compute_metrics_vectorized8_rectangular(const global int* restrict nodes, global int8* restrict queue_, const int n_nodes, const global edge_t* restrict edges, const global edge_t* restrict edges_reverse, const global edge_t* restrict edges_weights, global metrics_tt* metriche /*<RANK,LIVELLO>*/, const int max_adj_dept, const int max_adj_reverse_dept)
{
	local int something_changed;
	int something_changed_for_me;
	int work_item = get_global_id(0);
	int work_item_local_index = get_local_id(0);
	int work_group_size = get_local_size(0);
	int work_group = get_group_id(0);
	int global_queue_size = (n_nodes + 7) / 8;
	int local_queue_size = min(work_group_size, global_queue_size); //non è la lunghezza dalla coda globale ma la lunghezza di cui si deve occupare questo work group.

	bool work_item_outside_range = work_item >= global_queue_size || work_item_local_index >= local_queue_size;

	do {
		if (work_item_local_index == 0)
			something_changed = 0;

		if (!work_item_outside_range)
			something_changed_for_me = compute_metrics_vectorized8_rectangular_item(nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept, max_adj_reverse_dept);

		if (something_changed_for_me)
			something_changed = 1;

		barrier(CLK_LOCAL_MEM_FENCE);
	} while (something_changed > 0);

	//compute_metrics_vectorized8_rectangular_item(nodes, queue_, n_nodes, edges, edges_reverse, edges_weights, metriche, max_adj_dept ,max_adj_reverse_dept);
}