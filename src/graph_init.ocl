#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics : enable

int matrix_to_array_indexes(int i, int j, int row_len){
	return i * row_len + j;
}

int compare (int2 V1, int2 V2){
	if(V1.y == V2.y){
		return (V1.x > V2.x) ? 1 : -1; //NOTA: è diverso da quello implementato nel sort, perché in quel caso abbiamo dei criteri diversi su come definire un elemento maggiore di un altro.
	}
	return (V1.y > V2.y) ? 1 : -1;
}

int gt (int2 V1, int2 V2){
	return compare(V1, V2) > 0;
}

//ricerca delle leaf da cui cominciare la BFS
kernel void entry_discover(const int n_nodes, global bool * restrict edges, volatile global int *n_entries, global int * entries)
{
	int i = get_global_id(0);
	if(i >= n_nodes) return;

	//printf("input params for %d -> n_nodes: %d, nodes: %d, edges: %d, n_entries: %d, entries: %d.\n", i, n_nodes, nodes, edges, *n_entries, entries);

	for(int j=0; j<n_nodes; j++){
		if(edges[matrix_to_array_indexes(j,i,n_nodes)] != 0){ //per cercare le root invece delle leaf invertire i e j
			return;
		}
	}

	entries[i] = 1;

	//int old_n_entries = atomic_inc(n_entries);  //incremento il puntatore alla lista di entries per essere sicuro che nessuno scriva in quella posizione.
	//atomic_xchg(&entries[old_n_entries], i); //essendo sicuro che la posizione non è stata scritta inserisco il mio dato senza paura di sovrascrivere qualcosa.

	return;
}


kernel void compute_metrics(global int * restrict nodes, global int *queue_, global int *next_queue_, const int n_nodes, global bool * restrict edges, volatile global int2 *metriche /*<RANK,LIVELLO>*/)
{
	int i = get_global_id(0);
	int current_node_index = i;
	if(i >= n_nodes){
		return;
	} 

	if(queue_[current_node_index] <= 0)return;
	//se sono stato messo in coda un numero di volte pari al numero dei miei parent, allora posso proseguire, altrimenti non faccio nulla.
	//in particolare proseguire significa calcolare la metrica dai miei parent scegliendo quella più pesante e mettere in coda i miei figli.

	//per controllare di essere stato messo in coda un numero sufficiente di volte, l'int2 delle metriche viene inizializzato con il numero dei parent nella y.
	//in questo modo ogni volta che il nodo viene messo in coda può decrementare il suo y fino a quando non diventa 0, a qual punto può procedere al calcolo del rank.
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	metriche[i].y = metriche[i].y - queue_[current_node_index];
	queue_[current_node_index]  = 0;
	//printf("%d, %d, %d\n", current_node_index, metriche[i].y, queue_[current_node_index]);
	if(metriche[i].y > 0)return;
	metriche[current_node_index] = (int2)(nodes[current_node_index],0);
	//calcolo il livello del nodo attuale e il suo rank a partire dai parent
	int2 metrics_with_this_parent;
	for(int parent = 0; parent<n_nodes; parent++){
		int edge_weight = edges[matrix_to_array_indexes(parent, i, n_nodes)]; //controllo tutti i parent di current_node
		if(edge_weight > 0){
			int weight_with_this_parent = edge_weight + metriche[parent].x + nodes[current_node_index];
			int level_with_this_parent = metriche[parent].y+1;
			metrics_with_this_parent = (int2)(weight_with_this_parent, level_with_this_parent);
			if(gt(metrics_with_this_parent, metriche[current_node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
				metriche[current_node_index] = metrics_with_this_parent;
		}
	}

	for(int j=0; j<n_nodes; j++){
		int adiacent = edges[matrix_to_array_indexes(current_node_index, j, n_nodes)];
		if(adiacent > 0){
			atomic_inc(&next_queue_[j]);
		}
	}
}

/**
 * In questa implementazione l'idea è simile ad una ricerca in ampiezza.
 * Per ogni nodo si calcola il suo peso e si aggiungono i suoi figli alla coda.
 * Il problema di questa implementazione è che ogni nodo viene aggiunto alla coda molte volte e quindi questo algoritmo viene ripetuto molte volte per ogni nodo.
 * Questo impiegava circa due secondi per 2048 elementi, l'implementazione successiva mezzo secondo.
 */
kernel void compute_metrics_first_implementation(global int * restrict nodes, global int *queue_, global int *next_queue_, const int n_nodes, global bool * restrict edges, global int2 *metriche /*<RANK,LIVELLO>*/)
{
	//TODO: queue count non più necessario, ma forse nex_queue_count necessario per capire se ho finito di calcolare tutte le metriche o se devo ciclare ancora.

	int i = get_global_id(0);
	//int ii = get_group_id(0); //0
	//int iii = get_global_size(0); //64
	//int iiii = get_local_id(0); //idem ad global id
	//int iiiii = get_local_size(0); //64

	//printf("input params for %d -> n_nodes: %d, nodes: %d, edges: %d, queue count: %d, next queue count: %d.\n", i, n_nodes, nodes, edges, *queue_count, next_queue_count);
	if(i >= n_nodes){
		//printf("esco: i: %d, queue_count: %d, next_queue_count: %d, n_nodes: %d.\n", i, *queue_count, *next_queue_count, n_nodes);
		return;
	} 

	int current_node_index = queue_[i]; // i corrisponde al current_node_index ma devo controllare che qualcuno lo abbia effettivamente aggiunto alla coda, la momento dentro la coda ritrovo il suo indice il che è ridontante ma probabilmente questo cambierà a breve.
	if(current_node_index < 0){
		//printf("esco: i: %d, queue_count: %d, next_queue_count: %d, n_nodes: %d.\n", i, *queue_count, *next_queue_count, n_nodes);
		return;
	} 

	//calcolo del rank e del livello del nodo
	metriche[current_node_index] = (int2)(nodes[current_node_index],0);
	//TODO: se questo passaggio lo facesse il parent inveche che il figlio risparmieremmo questo ciclo for che è molto simile al successivo in cui si controllano i child.
	int2 metrics_with_this_parent;
	for(int parent=0; parent < n_nodes; parent++){
		int weight_of_link_with_parent = edges[matrix_to_array_indexes(parent, current_node_index, n_nodes)];
		if(weight_of_link_with_parent > 0) {
			int weight_with_this_parent = weight_of_link_with_parent + metriche[parent].x + nodes[current_node_index];
			int level_with_this_parent = metriche[parent].y+1;
			metrics_with_this_parent = (int2)(weight_with_this_parent, level_with_this_parent);
			if(gt(metrics_with_this_parent, metriche[current_node_index]))//prendo il maggiore peso peggiore che il nodo ottiene con i suoi parent.
				metriche[current_node_index] = metrics_with_this_parent;
			//metriche[current_node_index].x = max(weight_with_this_parent, metriche[current_node_index].x);
			//metriche[current_node_index].y = max(metriche[current_node_index].y, level_with_this_parent);
		}
	}

	//poi si controllano tutti i figli e si aggiungono alla coda per implementare la BFS.
	//ogni nodo può esssere aggiunto alla coda più volte se ha più parent, e questo, anche se meno efficiente, mi permette di svolgere questo kernel in parallelo senza problemi.
	for(int j=0; j<n_nodes; j++){
		int adiacent = edges[matrix_to_array_indexes(current_node_index, j, n_nodes)];
		if(adiacent > 0){
			//printf("edge tra: %d -> %d\n", current_node_index, j);
			//int old_queue_count = atomic_inc(next_queue_count);//TODO: cambiare questa cosa che probabilmente causerà molto overhead e magari controllare su host se l'array queue è vuoto.
			//atomic_xchg(&next_queue_[current_node_index], j);
			next_queue_[j] = j;
		}
	}

	//printf("work item: (%d), dimensione code: (%d, %d), nodo: (%d, %d), nuova metrica: (%d, %d).\n", i, *queue_count, *next_queue_count, current_node_index, nodes[current_node_index], metriche[current_node_index].x, metriche[current_node_index].y);
}

// Comincio la BFS.

	//int *q = alloc(); //TODO: Come faccio a creare una coda?
	//Ha senso creare una coda in local memory visto che la procedura BFS va richiamata ricorsivamenteper ogni task nella coda
	//Ogni WI potrebbe aggiungere man mano i task alla coda, mentre altri WI processano questi nuovi task in coda?
	//


	//PER OGNI NODO:
		//BREADTH FIRST SEARCH PER CALCOLARE I LIVELLI, CIOÈ GLI INSIEMI DI TASK INDIPENDENTI E CHE QUINDI POSSONO ESSERE PARALLELIZZATE
		
		//BREADTH FIRST SEARCH PER CALCOLARE IL COSTO COMPLESSIVO DI UN NODO DATI I SUOI PARENT. (DTC - DATA TRANSFER COST)
		
		//(BREADTH FIRST SEARCH)? PER CALCOLARE RANK DEI SUOI PARENT E SCEGLIERE IL MAX. (RPT - RANK of PREDECESSOR TASK)
		
		//CALCOLO DEL SUO RANK DATO DA: ROUND(ACC+DTC+RPT); (con ACC - AVERAGE COMPUTATIONAL COST, costante nel nostro caso ed è la quantità di dati trasmessi, perché assumiamo che tutti i processori siano uguali)


	//ALLA FINE LA PRIORITÀ È DATA DA:
		//LIVELLO PIÙ BASSO
		
		//SE STESSO LIVELLO ALLORA RANK PIÙ ALTO

		//SE STESSO RANK ALLORA ACC PIÙ BASSO


	//IL PROCESSORE VIENE ASSEGNATO IN BASE:
		//PER OGNI TASK SI SCEGLIE IL PROCESSORE CON EFT - ESTIMATED FINAL TIME PIÙ PICCOLO, CHE VIENE CALCOLATO RICORSIVAMENTE A PARTIRE DAI PARENT DEL TASK
